{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trp7TOZhauPY"
      },
      "source": [
        "# Installing and Setting up PySpark and Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TgDAF25SUzM",
        "outputId": "917008eb-3697-499b-d587-9e57d5f4dada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=f647e69f47af06a12c0219df3fc4080ac2781860d1ecdb30f3fc238ac7d92b03\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.8)\n",
            "Dataset URL: https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data\n",
            "License(s): CC0-1.0\n",
            "Downloading craigslist-carstrucks-data.zip to /content\n",
            " 91% 238M/262M [00:02<00:00, 105MB/s]\n",
            "100% 262M/262M [00:02<00:00, 104MB/s]\n",
            "Archive:  craigslist-carstrucks-data.zip\n",
            "  inflating: vehicles.csv            \n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install pyspark\n",
        "!pip install kaggle\n",
        "\n",
        "# Setup Kaggle API to download dataset\n",
        "!mkdir ~/.kaggle\n",
        "!kaggle datasets download -d austinreese/craigslist-carstrucks-data\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip craigslist-carstrucks-data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSTboCPld0Ib"
      },
      "source": [
        "# Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPit-n0sUJRJ",
        "outputId": "a2bc194b-06bc-4fa6-abb4-c92e90a579a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PySpark Reading Time: 43.94860100746155 seconds\n",
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- url: string (nullable = true)\n",
            " |-- region: string (nullable = true)\n",
            " |-- region_url: string (nullable = true)\n",
            " |-- price: string (nullable = true)\n",
            " |-- year: string (nullable = true)\n",
            " |-- manufacturer: string (nullable = true)\n",
            " |-- model: string (nullable = true)\n",
            " |-- condition: string (nullable = true)\n",
            " |-- cylinders: string (nullable = true)\n",
            " |-- fuel: string (nullable = true)\n",
            " |-- odometer: string (nullable = true)\n",
            " |-- title_status: string (nullable = true)\n",
            " |-- transmission: string (nullable = true)\n",
            " |-- VIN: string (nullable = true)\n",
            " |-- drive: string (nullable = true)\n",
            " |-- size: string (nullable = true)\n",
            " |-- type: string (nullable = true)\n",
            " |-- paint_color: string (nullable = true)\n",
            " |-- image_url: string (nullable = true)\n",
            " |-- description: string (nullable = true)\n",
            " |-- county: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- lat: string (nullable = true)\n",
            " |-- long: string (nullable = true)\n",
            " |-- posting_date: string (nullable = true)\n",
            "\n",
            "+----------+--------------------+--------------------+--------------------+-----+----+------------+-----+---------+---------+----+--------+------------+------------+----+-----+----+----+-----------+---------+-----------+------+-----+----+----+------------+\n",
            "|        id|                 url|              region|          region_url|price|year|manufacturer|model|condition|cylinders|fuel|odometer|title_status|transmission| VIN|drive|size|type|paint_color|image_url|description|county|state| lat|long|posting_date|\n",
            "+----------+--------------------+--------------------+--------------------+-----+----+------------+-----+---------+---------+----+--------+------------+------------+----+-----+----+----+-----------+---------+-----------+------+-----+----+----+------------+\n",
            "|7222695916|https://prescott....|            prescott|https://prescott....| 6000|NULL|        NULL| NULL|     NULL|     NULL|NULL|    NULL|        NULL|        NULL|NULL| NULL|NULL|NULL|       NULL|     NULL|       NULL|  NULL|   az|NULL|NULL|        NULL|\n",
            "|7218891961|https://fayar.cra...|        fayetteville|https://fayar.cra...|11900|NULL|        NULL| NULL|     NULL|     NULL|NULL|    NULL|        NULL|        NULL|NULL| NULL|NULL|NULL|       NULL|     NULL|       NULL|  NULL|   ar|NULL|NULL|        NULL|\n",
            "|7221797935|https://keys.crai...|        florida keys|https://keys.crai...|21000|NULL|        NULL| NULL|     NULL|     NULL|NULL|    NULL|        NULL|        NULL|NULL| NULL|NULL|NULL|       NULL|     NULL|       NULL|  NULL|   fl|NULL|NULL|        NULL|\n",
            "|7222270760|https://worcester...|worcester / centr...|https://worcester...| 1500|NULL|        NULL| NULL|     NULL|     NULL|NULL|    NULL|        NULL|        NULL|NULL| NULL|NULL|NULL|       NULL|     NULL|       NULL|  NULL|   ma|NULL|NULL|        NULL|\n",
            "|7210384030|https://greensbor...|          greensboro|https://greensbor...| 4900|NULL|        NULL| NULL|     NULL|     NULL|NULL|    NULL|        NULL|        NULL|NULL| NULL|NULL|NULL|       NULL|     NULL|       NULL|  NULL|   nc|NULL|NULL|        NULL|\n",
            "+----------+--------------------+--------------------+--------------------+-----+----+------------+-----+---------+---------+----+--------+------------+------------+----+-----+----+----+-----------+---------+-----------+------+-----+----+----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F\n",
        "import time\n",
        "from pyspark.sql.functions import col, lit\n",
        "\n",
        "# Create SparkSession (required to work with PySpark)\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "# Start timer and read the CSV file into a PySpark DataFrame\n",
        "start_time = time.time()\n",
        "df_spark = spark.read.csv(\"/content/vehicles.csv\", header=True, inferSchema=True)\n",
        "end_time = time.time()\n",
        "\n",
        "# Display time taken to read the file\n",
        "print(f\"PySpark Reading Time: {end_time - start_time} seconds\")\n",
        "\n",
        "# Display schema of the DataFrame\n",
        "df_spark.printSchema()\n",
        "\n",
        "# Show the first 5 rows of the dataset\n",
        "df_spark.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIz-axk4gIVr"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTWYY-9XjIoU"
      },
      "outputs": [],
      "source": [
        "# Drop columns that are not useful for our analysis or model\n",
        "columns_to_drop = ['url', 'region', 'region_url', 'title_status', 'VIN', 'size', 'image_url', 'lat', 'long', 'county', 'description']\n",
        "df_spark = df_spark.drop(*columns_to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkaWn7D9ErHc",
        "outputId": "5b65d011-2129-461e-b341-60c07760167e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+----+------------+-----+---------+---------+----+--------+------------+-----+----+-----------+-----+------------+\n",
            "|        id|price|year|manufacturer|model|condition|cylinders|fuel|odometer|transmission|drive|type|paint_color|state|posting_date|\n",
            "+----------+-----+----+------------+-----+---------+---------+----+--------+------------+-----+----+-----------+-----+------------+\n",
            "|7222695916| 6000|NULL|        NULL| NULL|     NULL|     NULL|NULL|    NULL|        NULL| NULL|NULL|       NULL|   az|        NULL|\n",
            "|7218891961|11900|NULL|        NULL| NULL|     NULL|     NULL|NULL|    NULL|        NULL| NULL|NULL|       NULL|   ar|        NULL|\n",
            "|7221797935|21000|NULL|        NULL| NULL|     NULL|     NULL|NULL|    NULL|        NULL| NULL|NULL|       NULL|   fl|        NULL|\n",
            "|7222270760| 1500|NULL|        NULL| NULL|     NULL|     NULL|NULL|    NULL|        NULL| NULL|NULL|       NULL|   ma|        NULL|\n",
            "|7210384030| 4900|NULL|        NULL| NULL|     NULL|     NULL|NULL|    NULL|        NULL| NULL|NULL|       NULL|   nc|        NULL|\n",
            "+----------+-----+----+------------+-----+---------+---------+----+--------+------------+-----+----+-----------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LY1BMpMWULHw",
        "outputId": "4d6fa501-246e-43d9-89f2-c1aac48629de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            " |-- manufacturer: string (nullable = true)\n",
            " |-- model: string (nullable = true)\n",
            " |-- condition: string (nullable = true)\n",
            " |-- cylinders: string (nullable = true)\n",
            " |-- fuel: string (nullable = true)\n",
            " |-- odometer: double (nullable = true)\n",
            " |-- transmission: string (nullable = true)\n",
            " |-- drive: string (nullable = true)\n",
            " |-- type: string (nullable = true)\n",
            " |-- paint_color: string (nullable = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- posting_date: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Convert columns to appropriate data types for analysis and modeling\n",
        "df_spark = df_spark.withColumn(\"price\", col(\"price\").cast(\"double\"))  # Price should be numeric\n",
        "df_spark = df_spark.withColumn(\"year\", col(\"year\").cast(\"int\"))  # Year should be an integer\n",
        "df_spark = df_spark.withColumn(\"odometer\", col(\"odometer\").cast(\"double\"))  # Odometer should be numeric\n",
        "\n",
        "# Print the updated schema to verify data types\n",
        "df_spark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_OSdp5TcPPW"
      },
      "outputs": [],
      "source": [
        "# Fill missing categorical values with 'unknown' for consistency\n",
        "df_spark = df_spark.fillna({\n",
        "    \"cylinders\": \"unknown\",\n",
        "    \"fuel\": \"unknown\",\n",
        "    \"transmission\": \"unknown\",\n",
        "    \"drive\": \"unknown\",\n",
        "    \"paint_color\": \"unknown\",\n",
        "    \"type\": \"unknown\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgcfFjb1FwvH",
        "outputId": "3efe3976-dd2c-45d6-a923-e9fdb0c334da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+----+------------+-----+---------+---------+-------+--------+------------+-------+-------+-----------+-----+------------+\n",
            "|        id|  price|year|manufacturer|model|condition|cylinders|   fuel|odometer|transmission|  drive|   type|paint_color|state|posting_date|\n",
            "+----------+-------+----+------------+-----+---------+---------+-------+--------+------------+-------+-------+-----------+-----+------------+\n",
            "|7222695916| 6000.0|NULL|        NULL| NULL|     NULL|  unknown|unknown|    NULL|     unknown|unknown|unknown|    unknown|   az|        NULL|\n",
            "|7218891961|11900.0|NULL|        NULL| NULL|     NULL|  unknown|unknown|    NULL|     unknown|unknown|unknown|    unknown|   ar|        NULL|\n",
            "|7221797935|21000.0|NULL|        NULL| NULL|     NULL|  unknown|unknown|    NULL|     unknown|unknown|unknown|    unknown|   fl|        NULL|\n",
            "|7222270760| 1500.0|NULL|        NULL| NULL|     NULL|  unknown|unknown|    NULL|     unknown|unknown|unknown|    unknown|   ma|        NULL|\n",
            "|7210384030| 4900.0|NULL|        NULL| NULL|     NULL|  unknown|unknown|    NULL|     unknown|unknown|unknown|    unknown|   nc|        NULL|\n",
            "+----------+-------+----+------------+-----+---------+---------+-------+--------+------------+-------+-------+-----------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RMB0jt6mdGL",
        "outputId": "4ad20239-3e7e-40c0-e259-f0822f66c800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "|year|\n",
            "+----+\n",
            "|1901|\n",
            "|1902|\n",
            "|1903|\n",
            "|1905|\n",
            "|1909|\n",
            "|1910|\n",
            "|1913|\n",
            "|1915|\n",
            "|1916|\n",
            "|1918|\n",
            "|1920|\n",
            "|1921|\n",
            "|1922|\n",
            "|1923|\n",
            "|1924|\n",
            "|1925|\n",
            "|1926|\n",
            "|1927|\n",
            "|1928|\n",
            "|1929|\n",
            "+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Filter record with invalid year\n",
        "df_spark = df_spark.filter((col(\"year\") > 1900) & (col(\"year\") <= 2024))\n",
        "\n",
        "df_spark.select(\"year\").distinct().orderBy(\"year\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urfA12sCcia1",
        "outputId": "8caafe0d-fd23-41d4-e717-a702551b5863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---+\n",
            "|year|age|\n",
            "+----+---+\n",
            "|2014| 10|\n",
            "|2010| 14|\n",
            "|2020|  4|\n",
            "|2017|  7|\n",
            "|2013| 11|\n",
            "|2012| 12|\n",
            "|2016|  8|\n",
            "|2019|  5|\n",
            "|2016|  8|\n",
            "|2011| 13|\n",
            "+----+---+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import lit\n",
        "\n",
        "# Calculate age based on the current year\n",
        "current_year = 2024\n",
        "df_spark = df_spark.withColumn(\"age\", lit(current_year) - col(\"year\"))\n",
        "\n",
        "# Show result\n",
        "df_spark.select(\"year\", \"age\").show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XL2rs26eMtM"
      },
      "source": [
        "# EDA (Exploratory Data Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrFdPfRvjiar",
        "outputId": "51bcb784-9e0b-4b97-c6bb-2c5a6e024357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|year|count|\n",
            "+----+-----+\n",
            "|1901|    3|\n",
            "|1902|    1|\n",
            "|1903|   12|\n",
            "|1905|    1|\n",
            "|1909|    1|\n",
            "|1910|    2|\n",
            "|1913|    2|\n",
            "|1915|    1|\n",
            "|1916|    2|\n",
            "|1918|    1|\n",
            "+----+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Number of vehicles per year\n",
        "df_spark.groupBy(\"year\").count().orderBy(\"year\").show(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rYKVcWojltY",
        "outputId": "fd261f8e-8fc0-4785-f5b4-46a6d94aedd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+------------------+-----------------+\n",
            "|summary|               price|          odometer|              age|\n",
            "+-------+--------------------+------------------+-----------------+\n",
            "|  count|              425827|            421332|           425929|\n",
            "|   mean|   75279.43337552574| 98224.43318807971|12.76114563694888|\n",
            "| stddev|1.2197335159309383E7|214118.86783963133|9.431055628948746|\n",
            "|    min|                 0.0|               0.0|                2|\n",
            "|    max|       3.736928711E9|             1.0E7|              123|\n",
            "+-------+--------------------+------------------+-----------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Descriptive statistics for numeric columns\n",
        "df_spark.describe([\"price\", \"odometer\", \"age\"]).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJHnQJ0Ll3dH",
        "outputId": "ab9b10a8-1359-43c3-83e4-b14e3444bce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+------------+--------------------+\n",
            "|year|  price|manufacturer|               model|\n",
            "+----+-------+------------+--------------------+\n",
            "|2014|33590.0|         gmc|sierra 1500 crew ...|\n",
            "|2010|22590.0|   chevrolet|      silverado 1500|\n",
            "|2020|39590.0|   chevrolet| silverado 1500 crew|\n",
            "|2017|30990.0|      toyota|tundra double cab sr|\n",
            "|2013|15000.0|        ford|           f-150 xlt|\n",
            "|2012|27990.0|         gmc|sierra 2500 hd ex...|\n",
            "|2016|34590.0|   chevrolet|silverado 1500 do...|\n",
            "|2019|35000.0|      toyota|              tacoma|\n",
            "|2016|29990.0|   chevrolet|colorado extended...|\n",
            "|2011|38590.0|   chevrolet|corvette grand sport|\n",
            "|1992| 4500.0|        jeep|            cherokee|\n",
            "|2017|32990.0|        jeep|wrangler unlimite...|\n",
            "|2017|24590.0|   chevrolet|silverado 1500 re...|\n",
            "|2016|30990.0|   chevrolet|colorado crew cab...|\n",
            "|2014|27990.0|      toyota|tacoma access cab...|\n",
            "|2016|37990.0|   chevrolet|  camaro ss coupe 2d|\n",
            "|2014|33590.0|      toyota|tundra crewmax sr...|\n",
            "|2019|30990.0|        ford|ranger supercrew ...|\n",
            "|2018|27990.0|      nissan|frontier crew cab...|\n",
            "|2011|    0.0|        jeep|             compass|\n",
            "+----+-------+------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Filter cars priced under $100,000 and manufactured 1990 or later\n",
        "df_filtered = df_spark.filter((col(\"price\") < 100000) & (col(\"year\") >= 1990))\n",
        "df_filtered.select(\"year\", \"price\", \"manufacturer\", \"model\").show(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbjFv_xOot-B",
        "outputId": "87edc477-2c04-4d1a-ade1-8d14331f84e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+------------+--------------------+\n",
            "|year|  price|manufacturer|               model|\n",
            "+----+-------+------------+--------------------+\n",
            "|2014|33590.0|         gmc|sierra 1500 crew ...|\n",
            "|2010|22590.0|   chevrolet|      silverado 1500|\n",
            "|2020|39590.0|   chevrolet| silverado 1500 crew|\n",
            "|2017|30990.0|      toyota|tundra double cab sr|\n",
            "|2013|15000.0|        ford|           f-150 xlt|\n",
            "+----+-------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Use PySpark SQL\n",
        "df_spark.createOrReplaceTempView(\"vehicles\")\n",
        "spark.sql(\"SELECT year, price, manufacturer, model FROM vehicles WHERE price < 100000 AND year >= 1990\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v58WMwtIjmN7",
        "outputId": "d4eab109-2c67-4418-c2c7-5c3190a6b4e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+-------+\n",
            "|year|odometer|  price|\n",
            "+----+--------+-------+\n",
            "|2013|128000.0|15000.0|\n",
            "|1992|192000.0| 4500.0|\n",
            "|2001|144700.0|22500.0|\n",
            "|2004|176144.0| 3000.0|\n",
            "|2008|201300.0|17500.0|\n",
            "+----+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Filter car odometer > 100,000\n",
        "df_filtered = df_spark.filter(col(\"odometer\") > 100000)\n",
        "df_filtered.select(\"year\", \"odometer\", \"price\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkUO8V6AoyVU",
        "outputId": "5a749813-4435-4979-f796-2f0ff1414e2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+-------+\n",
            "|year|odometer|  price|\n",
            "+----+--------+-------+\n",
            "|2013|128000.0|15000.0|\n",
            "|1992|192000.0| 4500.0|\n",
            "|2001|144700.0|22500.0|\n",
            "|2004|176144.0| 3000.0|\n",
            "|2008|201300.0|17500.0|\n",
            "+----+--------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Use PySpark SQL\n",
        "spark.sql(\"SELECT year, odometer, price FROM vehicles WHERE odometer > 100000\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WT3RgKYo57w"
      },
      "source": [
        "## Comparing to PySpark and Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7A7aulc6HJ5"
      },
      "source": [
        "## PySpark version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pfksoemmjnzo",
        "outputId": "5f80a281-8d1e-4bec-96c3-4968c787df1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PySpark Reading Time: 18.788039207458496 seconds\n",
            "PySpark Processing Time: 0.2909984588623047 seconds\n"
          ]
        }
      ],
      "source": [
        "# Read data again\n",
        "start_time = time.time()\n",
        "df_spark = spark.read.csv(\"/content/vehicles.csv\", header=True, inferSchema=True)\n",
        "end_time = time.time()\n",
        "\n",
        "# Display time taken to read the file\n",
        "print(f\"PySpark Reading Time: {end_time - start_time} seconds\")\n",
        "\n",
        "# Set the current year for age calculation\n",
        "current_year = 2024\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Drop unused columns\n",
        "columns_to_drop =['url', 'region', 'region_url', 'title_status', 'VIN', 'size', 'image_url', 'lat', 'long', 'county', 'description']\n",
        "df_spark = df_spark.drop(*columns_to_drop)\n",
        "\n",
        "# Calculate age based on the current year\n",
        "df_spark = df_spark.withColumn(\"age\", lit(current_year) - col(\"year\"))\n",
        "\n",
        "# Convert columns to appropriate data types\n",
        "df_spark = df_spark.withColumn(\"price\", col(\"price\").cast(\"double\"))\n",
        "df_spark = df_spark.withColumn(\"year\", col(\"year\").cast(\"int\"))\n",
        "df_spark = df_spark.withColumn(\"odometer\", col(\"odometer\").cast(\"double\"))\n",
        "\n",
        "# Filter record with invalid year\n",
        "df_spark = df_spark.filter((col(\"year\") > 1900) & (col(\"year\") <= 2024))\n",
        "\n",
        "# Fill missing values with default values\n",
        "df_spark = df_spark.fillna({\n",
        "    \"cylinders\": \"unknown\",\n",
        "    \"fuel\": \"unknown\",\n",
        "    \"transmission\": \"unknown\",\n",
        "    \"drive\": \"unknown\",\n",
        "    \"paint_color\": \"unknown\",\n",
        "    \"type\": \"unknown\"\n",
        "})\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"PySpark Processing Time: {end_time - start_time} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_fiFB_U6CwP"
      },
      "source": [
        "## Pandas version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a86EBFey5wM6",
        "outputId": "7b13d863-fc8a-4241-d4b1-45b7e41d6e21"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pandas Reading Time: 33.5674831867218 seconds\n",
            "Pandas Processing Time: 2.1332733631134033 seconds\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "current_year = 2024\n",
        "\n",
        "# Start timer for reading the data\n",
        "start_time_read = time.time()\n",
        "\n",
        "# Read the CSV file into a pandas DataFrame\n",
        "df_pandas = pd.read_csv(\"/content/vehicles.csv\")\n",
        "\n",
        "end_time_read = time.time()\n",
        "print(f\"Pandas Reading Time: {end_time_read - start_time_read} seconds\")\n",
        "\n",
        "# Start timer for data processing\n",
        "start_time_process = time.time()\n",
        "\n",
        "# Drop unused columns\n",
        "columns_to_drop = ['url', 'region', 'region_url', 'title_status', 'VIN', 'size', 'image_url', 'lat', 'long', 'county', 'description']\n",
        "df_pandas = df_pandas.drop(columns=columns_to_drop)\n",
        "\n",
        "# Calculate age based on the current year\n",
        "df_pandas['age'] = current_year - df_pandas['year']\n",
        "\n",
        "# Convert columns to appropriate data types\n",
        "df_pandas['price'] = pd.to_numeric(df_pandas['price'], errors='coerce')\n",
        "df_pandas['year'] = pd.to_numeric(df_pandas['year'], errors='coerce')\n",
        "df_pandas['odometer'] = pd.to_numeric(df_pandas['odometer'], errors='coerce')\n",
        "\n",
        "# Filter records with invalid year\n",
        "df_pandas = df_pandas[(df_pandas['year'] > 1900) & (df_pandas['year'] <= 2024)]\n",
        "\n",
        "# Fill missing values with default values\n",
        "df_pandas.loc['cylinders']=df_pandas['cylinders'].fillna('unknown')\n",
        "df_pandas.loc['fuel']=df_pandas['fuel'].fillna('unknown')\n",
        "df_pandas.loc['transmission']=df_pandas['transmission'].fillna('unknown')\n",
        "df_pandas.loc['drive']=df_pandas['drive'].fillna('unknown')\n",
        "df_pandas.loc['paint_color']=df_pandas['paint_color'].fillna('unknown')\n",
        "df_pandas.loc['type']=df_pandas['type'].fillna('unknown')\n",
        "\n",
        "# End timer for data processing\n",
        "end_time_process = time.time()\n",
        "\n",
        "# Print processing time\n",
        "print(f\"Pandas Processing Time: {end_time_process - start_time_process} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "looab2QZmEty"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA1dXnWahMj-"
      },
      "source": [
        "## Step 1: Data Cleaning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocURbXja6gbN"
      },
      "source": [
        "### 1.1 Drop rows with missing values in important columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpcEtjeAhuJw"
      },
      "outputs": [],
      "source": [
        "# We remove rows that have missing values in the 'price', 'odometer', 'year', or 'manufacturer' columns.\n",
        "df_spark = df_spark.dropna(subset=['price', 'odometer', 'year', 'manufacturer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIjLguA-2D4c"
      },
      "source": [
        "### 1.2 Drop outliers using Z-score for numeric columns\n",
        "Calculate Z-scores and filter out records where Z-score > 2 (approximately 95% confidence interval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhcczUGJ2EYb"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import mean, stddev\n",
        "\n",
        "# Calculate mean and standard deviation for the numeric columns\n",
        "mean_price, stddev_price = df_spark.select(mean('price'), stddev('price')).first()\n",
        "mean_odometer, stddev_odometer = df_spark.select(mean('odometer'), stddev('odometer')).first()\n",
        "\n",
        "# Filter out outliers based on Z-score > 2\n",
        "df_spark = df_spark.filter(((df_spark['price'] - mean_price) / stddev_price).between(-2, 2))\n",
        "df_spark = df_spark.filter(((df_spark['odometer'] - mean_odometer) / stddev_odometer).between(-2, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-973rlw1sYk"
      },
      "source": [
        "## Step 2: Feature Engineering\n",
        "Convert categorical columns to numeric using StringIndexer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KELV2Z9I1rsM"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# Convert 'manufacturer' to numeric\n",
        "indexer_manufacturer = StringIndexer(inputCol=\"manufacturer\", outputCol=\"manufacturer_index\")\n",
        "df_spark = indexer_manufacturer.fit(df_spark).transform(df_spark)\n",
        "\n",
        "# Convert 'fuel' to numeric\n",
        "indexer_fuel = StringIndexer(inputCol=\"fuel\", outputCol=\"fuel_index\")\n",
        "df_spark = indexer_fuel.fit(df_spark).transform(df_spark)\n",
        "\n",
        "# Convert 'transmission' to numeric\n",
        "indexer_transmission = StringIndexer(inputCol=\"transmission\", outputCol=\"transmission_index\")\n",
        "df_spark = indexer_transmission.fit(df_spark).transform(df_spark)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He7K1LsV1yz0"
      },
      "source": [
        "## Step 3: Prepare Features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJDvWpyP6dri"
      },
      "source": [
        "### 3.1 Assemble features into a single vector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52hFSaiKMI6c",
        "outputId": "3f7411bf-dd3a-4956-bbc1-da5a560e4ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+----+------------+--------------------+---------+-----------+----+--------+------------+-------+------+-----------+-----+--------------------+---+------------------+----------+------------------+\n",
            "|        id|  price|year|manufacturer|               model|condition|  cylinders|fuel|odometer|transmission|  drive|  type|paint_color|state|        posting_date|age|manufacturer_index|fuel_index|transmission_index|\n",
            "+----------+-------+----+------------+--------------------+---------+-----------+----+--------+------------+-------+------+-----------+-----+--------------------+---+------------------+----------+------------------+\n",
            "|7316814884|33590.0|2014|         gmc|sierra 1500 crew ...|     good|8 cylinders| gas| 57923.0|       other|unknown|pickup|      white|   al|2021-05-04T12:31:...| 10|               7.0|       0.0|               1.0|\n",
            "|7316814758|22590.0|2010|   chevrolet|      silverado 1500|     good|8 cylinders| gas| 71229.0|       other|unknown|pickup|       blue|   al|2021-05-04T12:31:...| 14|               1.0|       0.0|               1.0|\n",
            "|7316814989|39590.0|2020|   chevrolet| silverado 1500 crew|     good|8 cylinders| gas| 19160.0|       other|unknown|pickup|        red|   al|2021-05-04T12:31:...|  4|               1.0|       0.0|               1.0|\n",
            "|7316743432|30990.0|2017|      toyota|tundra double cab sr|     good|8 cylinders| gas| 41124.0|       other|unknown|pickup|        red|   al|2021-05-04T10:41:...|  7|               2.0|       0.0|               1.0|\n",
            "|7316356412|15000.0|2013|        ford|           f-150 xlt|excellent|6 cylinders| gas|128000.0|   automatic|    rwd| truck|      black|   al|2021-05-03T14:02:...| 11|               0.0|       0.0|               0.0|\n",
            "+----------+-------+----+------------+--------------------+---------+-----------+----+--------+------------+-------+------+-----------+-----+--------------------+---+------------------+----------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv3Xv7s-1xjo"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# List of features to be used in the model\n",
        "features = ['year', 'odometer', 'manufacturer_index', 'fuel_index', 'transmission_index']\n",
        "\n",
        "# Assemble these features into a single feature vector\n",
        "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "df_with_features = assembler.transform(df_spark)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_features.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWN9de1WMHlr",
        "outputId": "64a60ac5-ef25-4188-cbfc-193fde5078fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+----+------------+--------------------+---------+-----------+----+--------+------------+-------+------+-----------+-----+--------------------+---+------------------+----------+------------------+--------------------+\n",
            "|        id|  price|year|manufacturer|               model|condition|  cylinders|fuel|odometer|transmission|  drive|  type|paint_color|state|        posting_date|age|manufacturer_index|fuel_index|transmission_index|            features|\n",
            "+----------+-------+----+------------+--------------------+---------+-----------+----+--------+------------+-------+------+-----------+-----+--------------------+---+------------------+----------+------------------+--------------------+\n",
            "|7316814884|33590.0|2014|         gmc|sierra 1500 crew ...|     good|8 cylinders| gas| 57923.0|       other|unknown|pickup|      white|   al|2021-05-04T12:31:...| 10|               7.0|       0.0|               1.0|[2014.0,57923.0,7...|\n",
            "|7316814758|22590.0|2010|   chevrolet|      silverado 1500|     good|8 cylinders| gas| 71229.0|       other|unknown|pickup|       blue|   al|2021-05-04T12:31:...| 14|               1.0|       0.0|               1.0|[2010.0,71229.0,1...|\n",
            "|7316814989|39590.0|2020|   chevrolet| silverado 1500 crew|     good|8 cylinders| gas| 19160.0|       other|unknown|pickup|        red|   al|2021-05-04T12:31:...|  4|               1.0|       0.0|               1.0|[2020.0,19160.0,1...|\n",
            "|7316743432|30990.0|2017|      toyota|tundra double cab sr|     good|8 cylinders| gas| 41124.0|       other|unknown|pickup|        red|   al|2021-05-04T10:41:...|  7|               2.0|       0.0|               1.0|[2017.0,41124.0,2...|\n",
            "|7316356412|15000.0|2013|        ford|           f-150 xlt|excellent|6 cylinders| gas|128000.0|   automatic|    rwd| truck|      black|   al|2021-05-03T14:02:...| 11|               0.0|       0.0|               0.0|(5,[0,1],[2013.0,...|\n",
            "+----------+-------+----+------------+--------------------+---------+-----------+----+--------+------------+-------+------+-----------+-----+--------------------+---+------------------+----------+------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dBnRYFi2oKa"
      },
      "source": [
        "### 3.2 Normalize the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d2gyo-z2nZP"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StandardScaler\n",
        "\n",
        "# Apply standard scaling to normalize the feature vector (zero mean, unit variance)\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
        "scaler_model = scaler.fit(df_with_features)\n",
        "df_with_scaled_features = scaler_model.transform(df_with_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooqP4h5s2uxi"
      },
      "source": [
        "## Step 4: Train-Test Split\n",
        "\n",
        "### Split data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzZoN2ci2xXp"
      },
      "outputs": [],
      "source": [
        "# We use an 80-20 split for training and testing the model.\n",
        "train_data, test_data = df_with_scaled_features.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ikrDiWi23KS"
      },
      "source": [
        "## Step 5: Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0moalZEl25Rk"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "\n",
        "# Initialize the Decision Tree model\n",
        "dt = DecisionTreeRegressor(featuresCol=\"scaled_features\", labelCol=\"price\")\n",
        "\n",
        "# Train the model on the training data\n",
        "model = dt.fit(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpoVjXKT3AIL"
      },
      "source": [
        "## Step 6: Model Prediction & Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkM3qP0527Uk",
        "outputId": "771cbcd4-1349-4a04-ba01-b66f8d02d16b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 3196882364.4175835\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model using Mean Squared Error (MSE)\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Initialize the evaluator with MSE as the metric\n",
        "evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\", metricName=\"mse\")\n",
        "\n",
        "# Calculate MSE on the test data\n",
        "mse = evaluator.evaluate(predictions)\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some predictions and true price\n",
        "predictions.select(\"prediction\", \"price\").show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0KD3kDTB4Yo",
        "outputId": "248f1589-8e21-441e-9cf3-b3cf2c441bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+-------+\n",
            "|        prediction|  price|\n",
            "+------------------+-------+\n",
            "| 27996.44212123211|29590.0|\n",
            "|32221.372105014394|22990.0|\n",
            "|15170.110315854987|22590.0|\n",
            "| 27222.18423206329|38990.0|\n",
            "|15903.677673299802|30990.0|\n",
            "|32221.372105014394|21990.0|\n",
            "|32221.372105014394|38990.0|\n",
            "|12958.231119837319|27990.0|\n",
            "|14510.664509448616|18500.0|\n",
            "| 6788.213530244566|12977.0|\n",
            "|15170.110315854987|20977.0|\n",
            "|19350.165609252075|40590.0|\n",
            "|32221.372105014394|22488.0|\n",
            "|26991.509266720386|19995.0|\n",
            "| 27996.44212123211|30990.0|\n",
            "| 6788.213530244566| 5000.0|\n",
            "|22935.996920212005|27590.0|\n",
            "| 27222.18423206329|32590.0|\n",
            "| 27996.44212123211|30990.0|\n",
            "| 27996.44212123211|30990.0|\n",
            "+------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}